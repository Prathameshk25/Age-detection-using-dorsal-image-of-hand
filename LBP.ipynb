{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8cb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2 \n",
    "import os\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6235b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to create data set\n",
    "def create_dataset(old_path, young_path, adult_path):\n",
    "    \n",
    "    # list to store extracted features of an image\n",
    "    features = []\n",
    "    \n",
    "    # list to store class label, 1 for live, 0 for spoof\n",
    "    labels = []    \n",
    "    \n",
    "    radius = 3\n",
    "    \n",
    "    # number of neighbors to consider for LBP\n",
    "    n_points = 8 * radius \n",
    "    \n",
    "    # sampling type for LBP\n",
    "    METHOD = 'uniform'       \n",
    "    \n",
    "    path_array = [old_path, young_path, adult_path]\n",
    "    \n",
    "    for path in path_array:\n",
    "        \n",
    "        # storing all images in a folder in a list 'files'\n",
    "        files = os.listdir(path) \n",
    "        \n",
    "        # loop through the images in the folder\n",
    "        for img in files:\n",
    "            \n",
    "            \n",
    "            # reading the image in grayscale using cv2\n",
    "            image = cv2.imread(os.path.join(path + img), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            \n",
    "            # resizing the image so all images are of same size\n",
    "            \n",
    "            resized_img = cv2.resize(image, (300, 300))\n",
    "            \n",
    "            # Extracting features of an image using LBP\n",
    "               \n",
    "            lbp = local_binary_pattern(resized_img, n_points, radius, METHOD)\n",
    "                \n",
    "                 # Converting into 1-D array\n",
    "            fd=lbp.flatten()\n",
    "                \n",
    "            \n",
    "                \n",
    "                # label 1 for adult images, 0 for YOung images, 2 for old\n",
    "            class_identifier = 1\n",
    "            if 'Young' in path:\n",
    "                class_identifier = 0\n",
    "            elif 'Old' in path:\n",
    "                class_identifier = 2\n",
    "                \n",
    "             # appending exracted features to the list\n",
    "            features.append(fd) \n",
    "            \n",
    "            #adding corresponding class label to the list\n",
    "            labels.append(class_identifier)  \n",
    "                      \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "565e6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for differet folders\n",
    "training_old_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Train\\\\Old\\\\\"\n",
    "training_young_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Train\\\\Young\\\\\"\n",
    "training_adult_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Train\\\\Adult\\\\\"\n",
    "testing_old_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Test\\\\Old\\\\\"\n",
    "testing_young_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Test\\\\Young\\\\\"\n",
    "testing_adult_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp\\\\try0\\\\Test\\\\Adult\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e725535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data captured\n",
      "testing data captured\n"
     ]
    }
   ],
   "source": [
    "# LBP \n",
    "# Training and testing datasets\n",
    "\n",
    "x_train_data,y_train = create_dataset(training_old_path, training_young_path, training_adult_path)\n",
    "\n",
    "print('training data captured')\n",
    "\n",
    "x_test,y_test = create_dataset(testing_old_path,testing_young_path, testing_adult_path)\n",
    "print('testing data captured')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a090d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model\n",
    "\n",
    "lbp_clf = svm.SVC()\n",
    "lbp_clf.fit(x_train_data,y_train)\n",
    "\n",
    "# Predict on the test features, print the results\n",
    "\n",
    "lbp_y_pred = lbp_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09ceaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  \t\t0.9613953488372093\n",
      "Balanced accuracy: \t 0.7091666666666666\n",
      "Precision accuracy: \t 0.9411614943452861\n",
      "Recall Score: \t\t 0.9613953488372093\n",
      "F1 Score: \t\t 0.9613953488372093\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1995    5    0]\n",
      " [  69   31    0]\n",
      " [   9    0   41]]\n"
     ]
    }
   ],
   "source": [
    "#SVM Linear\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, lbp_y_pred)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, lbp_y_pred))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, lbp_y_pred,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, lbp_y_pred,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, lbp_y_pred,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, lbp_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed7d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  82.32558139534883 %\n",
      "Train Accuracy: 0.9974039460020768\n",
      "Test Accuracy: 0.8232558139534883\n",
      "Accuracy:  \t\t0.8232558139534883\n",
      "Balanced accuracy: \t 0.6351666666666667\n",
      "Precision accuracy: \t 0.5161943855170946\n",
      "Recall Score: \t\t 0.8232558139534883\n",
      "F1 Score: \t\t 0.8232558139534883\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1691  273   36]\n",
      " [  48   52    0]\n",
      " [  18    5   27]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier(max_depth=13)\n",
    "model_dt.fit(x_train_data, y_train)\n",
    "joblib.dump(model_dt,\"model_dt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred1)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred1))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred1,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred1,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred1,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d126a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9506976744186046\n",
      "Accuracy:  \t\t0.9506976744186046\n",
      "Balanced accuracy: \t 0.711\n",
      "Precision accuracy: \t 0.7909692876894501\n",
      "Recall Score: \t\t 0.9506976744186046\n",
      "F1 Score: \t\t 0.9506976744186046\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1966   25    9]\n",
      " [  59   41    0]\n",
      " [  11    2   37]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "model_rf.fit(x_train_data, y_train)\n",
    "joblib.dump(model_rf,\"model_rf\")\n",
    "\n",
    "y_pred2 = model_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",model_rf.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_rf.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred2)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred2))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred2,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred2,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred2,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf9e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8961578400830738\n",
      "Test Accuracy: 0.9548837209302325\n",
      "Accuracy:  \t\t0.9548837209302325\n",
      "Balanced accuracy: \t 0.7125\n",
      "Precision accuracy: \t 0.8345092992988018\n",
      "Recall Score: \t\t 0.9548837209302325\n",
      "F1 Score: \t\t 0.9548837209302325\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1975    4   21]\n",
      " [  58   41    1]\n",
      " [  13    0   37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "model_knn.fit(x_train_data, y_train)\n",
    "#joblib.dump(model_knn,\"model_knn\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred3)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred3))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred3,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred3,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred3,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15f3323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9595348837209302\n",
      "Accuracy:  \t\t0.9595348837209302\n",
      "Balanced accuracy: \t 0.7816666666666666\n",
      "Precision accuracy: \t 0.827947115849902\n",
      "Recall Score: \t\t 0.9595348837209302\n",
      "F1 Score: \t\t 0.9595348837209302\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1970   16   14]\n",
      " [  50   50    0]\n",
      " [   7    0   43]]\n"
     ]
    }
   ],
   "source": [
    "#xgboost classifier\n",
    "model_xgboost = XGBClassifier().fit(x_train_data, y_train)\n",
    "joblib.dump(model_xgboost,\"model_xgboost\")\n",
    "y_pred5 = model_xgboost.predict(x_test)\n",
    "print(\"XGboost\")\n",
    "print(\"Train Accuracy:\",model_xgboost.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_xgboost.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred5)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred5))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred5,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred5,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred5,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12583ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
